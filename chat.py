import asyncio
import json
import os
import logging
import sys
import subprocess
import google.generativeai as genai
from google.generativeai.types import Tool as GeminiTool, FunctionDeclaration
from dotenv import load_dotenv
from fastmcp import Client as MCPClient

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [BOT] - %(message)s')

def load_config():
    """ä» config.json åŠ è½½ command å’Œ urlã€‚"""
    try:
        load_dotenv()
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("ç¯å¢ƒå˜é‡ 'GOOGLE_API_KEY' æœªåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ã€‚")
        
        with open("config.json", 'r') as f:
            config_data = json.load(f)
        
        playwright_config = config_data["mcpServers"]["playwright"]
        command = [playwright_config["command"]] + playwright_config.get("args", [])
        url = playwright_config["url"]
        
        if not command or not url:
            raise ValueError("é…ç½®æ–‡ä»¶ä¸­å¿…é¡»åŒæ—¶åŒ…å« 'command' å’Œ 'url'ã€‚")
            
        logging.info("âœ… åˆå§‹é…ç½®åŠ è½½æˆåŠŸã€‚")
        return api_key, command, url
        
    except KeyError as e:
        logging.error(f"ğŸš¨ é…ç½®åŠ è½½å¤±è´¥: é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘å…³é”®å­—æ®µ {e}ã€‚")
        return None, None, None
    except Exception as e:
        logging.error(f"ğŸš¨ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return None, None, None

def convert_summaries_to_gemini_tools(tool_summaries: list) -> list[GeminiTool]:
    function_declarations = []
    for tool_summary in tool_summaries:
        input_schema = tool_summary.inputSchema
        properties = input_schema.get('properties', {})
        required = input_schema.get('required', [])
        
        for param_name, param_details in properties.items():
            if 'type' not in param_details:
                param_details['type'] = 'string'

        func_decl = FunctionDeclaration(
            name=tool_summary.name,
            description=tool_summary.description,
            parameters={
                "type": "object",
                "properties": properties,
                "required": required
            }
        )
        function_declarations.append(func_decl)
    return [GeminiTool(function_declarations=function_declarations)] if function_declarations else []

async def handle_single_request(user_input: str, command: list, url: str, model, chat_history: list):
    """
    ä¸ºå•æ¬¡ç”¨æˆ·è¯·æ±‚å¤„ç†å®Œæ•´çš„ Docker å¯åŠ¨ã€MCP è¿æ¥å’Œ Gemini äº¤äº’æµç¨‹ã€‚
    """
    process = None
    try:
        logging.info(f"ä¸ºæ–°è¯·æ±‚å¯åŠ¨ Docker è¿›ç¨‹: {' '.join(command)}")
        process = subprocess.Popen(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        wait_time = 3
        logging.info(f"ç­‰å¾… {wait_time} ç§’è®© Docker å®¹å™¨å¯åŠ¨...")
        await asyncio.sleep(wait_time)
        logging.info("ç»§ç»­æ‰§è¡Œï¼Œå°è¯•è¿æ¥...")

        async with MCPClient(url) as mcp_client:
            logging.info(f"âœ… æˆåŠŸè¿æ¥åˆ° MCP æœåŠ¡å™¨: {url}")
            
            # é‡æ–°å¼€å§‹ä¸€ä¸ªèŠå¤©ä¼šè¯ï¼Œä½†ä¿ç•™å†å²è®°å½•
            chat = model.start_chat(history=chat_history)
            
            print("ğŸ¤” Gemini æ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨å€™...")
            logging.info(f"æ­£åœ¨å°†ç”¨æˆ·è¾“å…¥å‘é€ç»™ Gemini: '{user_input}'")
            response = await chat.send_message_async(user_input)
            logging.info("å·²ä» Gemini æ”¶åˆ°å“åº”ã€‚æ­£åœ¨æ£€æŸ¥å·¥å…·è°ƒç”¨...")

            while response.candidates and response.candidates[0].content.parts[0].function_call:
                fc = response.candidates[0].content.parts[0].function_call
                tool_name = fc.name
                tool_args = {key: value for key, value in fc.args.items()}
                logging.info(f"Gemini è¯·æ±‚è°ƒç”¨å·¥å…·: {tool_name}ï¼Œå‚æ•°: {tool_args}")
                tool_result = await mcp_client.call_tool(tool_name, tool_args)
                logging.info(f"å·¥å…·è¿”å›ç»“æœ: {str(tool_result)[:300]}...")
                
                print("ğŸ¤” Gemini æ­£åœ¨å¤„ç†å·¥å…·ç»“æœï¼Œè¯·ç¨å€™...")
                logging.info("æ­£åœ¨å°†å·¥å…·ç»“æœå‘å› Gemini...")
                
                tool_response_part = {
                    "function_response": {
                        "name": tool_name,
                        "response": {"result": str(tool_result)}
                    }
                }
                
                response = await chat.send_message_async(tool_response_part)
                logging.info("å·²æ”¶åˆ° Gemini å¯¹å·¥å…·ç»“æœçš„æœ€ç»ˆå“åº”ã€‚")

            print(f"âœ¨ Gemini: {response.text}")
            # æ›´æ–°èŠå¤©å†å²
            chat_history.extend(chat.history)

    finally:
        if process:
            logging.info("æ­£åœ¨ç»ˆç»“æœ¬æ¬¡ä¼šè¯çš„ Docker è¿›ç¨‹...")
            process.terminate()
            process.wait()
            logging.info("Docker è¿›ç¨‹å·²ç»ˆç»“ã€‚")

async def main():
    """ä¸»ç¨‹åºï¼Œåˆå§‹åŒ–æ¨¡å‹ï¼Œå¹¶åœ¨å¾ªç¯ä¸­ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„ä¼šè¯ã€‚"""
    api_key, command, url = load_config()
    if not api_key or not command or not url:
        return

    # åœ¨ç¨‹åºå¯åŠ¨æ—¶ï¼Œåªè·å–ä¸€æ¬¡å·¥å…·å®šä¹‰
    # è¿™æ˜¯ä¸€ä¸ªä¼˜åŒ–ï¼Œå‡è®¾å·¥å…·é›†ä¸ä¼šåœ¨è¿è¡Œæ—¶æ”¹å˜
    print("æ­£åœ¨è¿›è¡Œä¸€æ¬¡æ€§å·¥å…·å®šä¹‰æ£€æŸ¥...")
    gemini_tools = await get_initial_tool_schema(command, url)
    if not gemini_tools:
        logging.error("æ— æ³•åœ¨å¯åŠ¨æ—¶è·å–å·¥å…·å®šä¹‰ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return
    print("âœ… å·¥å…·å®šä¹‰æ£€æŸ¥å®Œæˆã€‚")

    genai.configure(api_key=api_key)

    system_instruction = (
        "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä½¿ç”¨æä¾›çš„å·¥å…·æ¥æ§åˆ¶ä¸€ä¸ªç½‘ç»œæµè§ˆå™¨ï¼Œä»¥å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚"
        "è¯·ä»”ç»†åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶æŒ‰é¡ºåºè°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·æ¥è¾¾æˆç›®æ ‡ã€‚"
        "å¯¹äºç‰¹å®šä»»åŠ¡ï¼Œè¯·ä¼˜å…ˆé€‰æ‹©ç›´æ¥çš„ç½‘ç«™ã€‚ä¾‹å¦‚ï¼Œè¦æŸ¥è¯¢å¤©æ°”ï¼Œè¯·ç›´æ¥å¯¼èˆªåˆ°ä¸€ä¸ªå¤©æ°”ç½‘ç«™ï¼Œè€Œä¸æ˜¯åœ¨è°·æ­Œæœç´¢ã€‚"
        "ä½ çš„ç¬¬ä¸€æ­¥å‡ ä¹æ°¸è¿œæ˜¯è°ƒç”¨ 'browser_navigate' å·¥å…·ã€‚"
        "å¦‚æœé‡åˆ°ä»»ä½•æ— æ³•å¤„ç†çš„é¡µé¢ï¼ˆå¦‚'æˆ‘ä¸æ˜¯æœºå™¨äºº'éªŒè¯ç ï¼‰ï¼Œè¯·æŠ¥å‘Šè¿™ä¸ªé—®é¢˜å¹¶åœæ­¢å½“å‰ä»»åŠ¡ï¼Œè€Œä¸æ˜¯å°è¯•ä¸ä¹‹äº¤äº’ã€‚"
    )

    model = genai.GenerativeModel(
        model_name='gemini-2.5-flash',
        tools=gemini_tools,
        system_instruction=system_instruction
    )
    
    chat_history = [] # ç”¨äºåœ¨å¤šæ¬¡è¯·æ±‚ä¹‹é—´ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡

    print("\n--- ğŸ¤– Gemini æµè§ˆå™¨æ§åˆ¶æœºå™¨äººå·²å°±ç»ª (ä¼šè¯æ¨¡å¼) ---")
    print(f"âœ… æ¨¡å‹å·²è®¾ç½®ä¸º: {model.model_name}")
    print("ç°åœ¨å¯ä»¥ç›´æ¥ä¸‹è¾¾æŒ‡ä»¤ã€‚")

    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()

            if not user_input:
                print("âš ï¸ è¯·è¾“å…¥å†…å®¹ï¼Œæˆ–ä½¿ç”¨ 'exit' é€€å‡ºã€‚")
                continue

            if user_input.lower() in ['exit', 'quit']:
                print("ğŸ‘‹ æ­£åœ¨å…³é—­...")
                break
            
            # ä¸ºæ¯ä¸ªè¯·æ±‚è°ƒç”¨ç‹¬ç«‹çš„å¤„ç†å™¨
            await handle_single_request(user_input, command, url, model, chat_history)
        
        except Exception as e:
            logging.error(f"ğŸš¨ æœ¬è½®å¯¹è¯å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
            print("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·å°è¯•é‡æ–°æé—®ï¼Œæˆ–ä½¿ç”¨ 'exit' é€€å‡ºã€‚")

async def get_initial_tool_schema(command: list, url: str) -> list[GeminiTool] | None:
    """
    ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œä»…ç”¨äºåœ¨ç¨‹åºå¯åŠ¨æ—¶è·å–ä¸€æ¬¡å·¥å…·çš„ schemaã€‚
    """
    process = None
    try:
        process = subprocess.Popen(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        await asyncio.sleep(8)
        async with MCPClient(url) as mcp_client:
            tool_summaries = await mcp_client.list_tools()
            return convert_summaries_to_gemini_tools(tool_summaries)
    except Exception as e:
        logging.error(f"è·å–åˆå§‹å·¥å…·å®šä¹‰æ—¶å‡ºé”™: {e}")
        return None
    finally:
        if process:
            process.terminate()
            process.wait()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ã€‚")
